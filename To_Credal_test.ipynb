{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "try: c45 = reload(c45)\n",
    "except: import c45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_classes(l, classes):\n",
    "    classes = np.array(classes)\n",
    "    return [np.argmax([x==classes]) for x in l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying imprecise method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "class C45_credal:\n",
    "    \"\"\"Creates a decision tree with C4.5 algorithm\"\"\"\n",
    "    def __init__(self, pathToData,pathToNames, min_node_size=1, s=0, max_height=None):\n",
    "        self.filePathToData = pathToData\n",
    "        self.filePathToNames = pathToNames\n",
    "        self.data = []\n",
    "        self.classes = []\n",
    "        self.numAttributes = -1 \n",
    "        self.attrValues = {}\n",
    "        self.attributes = []\n",
    "        self.tree = None\n",
    "        self.min_node_size = min_node_size\n",
    "        self.s = s\n",
    "        self.max_height = max_height\n",
    "\n",
    "    def predict(self, x):\n",
    "        cur_node = self.tree\n",
    "        while not cur_node.isLeaf:\n",
    "            xidx = np.argmax(np.array(self.attributes)==cur_node.label)\n",
    "            t = cur_node.threshold if cur_node.threshold is not None else 0\n",
    "            if x[xidx]<=t:\n",
    "                cur_node = cur_node.children[0]\n",
    "            else:\n",
    "                cur_node = cur_node.children[1]\n",
    "        return cur_node.label\n",
    "    \n",
    "    def predict_list(self, xs):\n",
    "        ps = [self.predict(x) for x in xs]\n",
    "        return ps\n",
    "            \n",
    "\n",
    "    def fetchData(self):\n",
    "        with open(self.filePathToNames, \"r\") as file:\n",
    "            classes = file.readline()\n",
    "            self.classes = [x.strip() for x in classes.split(\",\")]\n",
    "            #add attributes\n",
    "            for line in file:\n",
    "                [attribute, values] = [x.strip() for x in line.split(\":\")]\n",
    "                values = [x.strip() for x in values.split(\",\")]\n",
    "                self.attrValues[attribute] = values\n",
    "        self.numAttributes = len(self.attrValues.keys())\n",
    "        self.attributes = list(self.attrValues.keys())\n",
    "        with open(self.filePathToData, \"r\") as file:\n",
    "            for line in file:\n",
    "                row = [x.strip() for x in line.split(\",\")]\n",
    "                if row != [] or row != [\"\"]:\n",
    "                    self.data.append(row)\n",
    "                    \n",
    "    def fetchDataSet(self, ds, y_feat):\n",
    "        self.classes = list(ds[y_feat].unique())\n",
    "        for f in ds.drop(y_feat,1):\n",
    "            self.attrValues[f] = list(ds[f].unique())        \n",
    "        \n",
    "        self.numAttributes = len(self.attrValues.keys())\n",
    "        self.attributes = list(self.attrValues.keys())\n",
    "        self.ds = ds\n",
    "\n",
    "    def preprocessData(self):\n",
    "        for index,row in enumerate(self.data):\n",
    "            for attr_index in range(self.numAttributes):\n",
    "                if(not self.isAttrDiscrete(self.attributes[attr_index])):\n",
    "                    self.data[index][attr_index] = float(self.data[index][attr_index])\n",
    "\n",
    "    def printTree(self):\n",
    "        self.printNode(self.tree)\n",
    "\n",
    "    def printNode(self, node, indent=\"\"):\n",
    "        if not node.isLeaf:\n",
    "            if node.threshold is None:\n",
    "                #discrete\n",
    "                for index,child in enumerate(node.children):\n",
    "                    if child.isLeaf:\n",
    "                        print(indent + node.label + \" = \" + self.attributes[index] + \" : \" + child.label)\n",
    "                    else:\n",
    "                        print(indent + node.label + \" = \" + self.attributes[index] + \" : \")\n",
    "                        self.printNode(child, indent + \"\t\")\n",
    "            else:\n",
    "                #numerical\n",
    "                leftChild = node.children[0]\n",
    "                rightChild = node.children[1]\n",
    "                if leftChild.isLeaf:\n",
    "                    print(indent + node.label + \" <= \" + str(node.threshold) + \" : \" + leftChild.label)\n",
    "                else:\n",
    "                    print(indent + node.label + \" <= \" + str(node.threshold)+\" : \")\n",
    "                    self.printNode(leftChild, indent + \"\t\")\n",
    "\n",
    "                if rightChild.isLeaf:\n",
    "                    print(indent + node.label + \" > \" + str(node.threshold) + \" : \" + rightChild.label)\n",
    "                else:\n",
    "                    print(indent + node.label + \" > \" + str(node.threshold) + \" : \")\n",
    "                    self.printNode(rightChild , indent + \"\t\")\n",
    "\n",
    "    def generateTree(self, data, attributes):\n",
    "        self.tree = self.recursiveGenerateTree(data, attributes, 0)\n",
    "\n",
    "    def recursiveGenerateTree(self, curData, curAttributes, height):\n",
    "        if len(curData) == 0:\n",
    "            #Fail\n",
    "            return None#Node(True, \"Fail\", None)\n",
    "        allSame = self.allSameClass(curData)\n",
    "        majClass = self.getMajClass(curData)\n",
    "        if allSame is not False:\n",
    "            #return a node with that class\n",
    "            return Node(True, allSame, None)\n",
    "        elif self.max_height is not None and height>=self.max_height:\n",
    "            return Node(True, allSame, None)\n",
    "        elif len(curAttributes) == 0:\n",
    "            #return a node with the majority class\n",
    "            return Node(True, majClass, None)\n",
    "        else:\n",
    "            (best,best_threshold,splitted) = self.splitAttribute(curData, curAttributes)\n",
    "            if best is None and best_threshold is None and splitted is None:\n",
    "                return Node(True, majClass, None)\n",
    "            \n",
    "            remainingAttributes = curAttributes[:]\n",
    "            remainingAttributes.remove(best)\n",
    "            node = Node(False, best, best_threshold)\n",
    "            children = [self.recursiveGenerateTree(subset, remainingAttributes, height+1) for subset in splitted]\n",
    "            node.children = [n if n is not None else Node(True, majClass, None) for n in children]\n",
    "            return node    \n",
    "        return node\n",
    "\n",
    "    def getMajClass(self, curData):\n",
    "        freq = [0]*len(self.classes)\n",
    "        for row in curData:\n",
    "            index = self.classes.index(row[-1])\n",
    "            freq[index] += 1\n",
    "        maxInd = freq.index(max(freq))\n",
    "        return self.classes[maxInd]\n",
    "\n",
    "    def allSameClass(self, data):\n",
    "        for row in data:\n",
    "            if row[-1] != data[0][-1]:\n",
    "                return False\n",
    "        return data[0][-1]\n",
    "\n",
    "    def isAttrDiscrete(self, attribute):\n",
    "        assert attribute in self.attributes, \"Attribute note listed\"\n",
    "        if len(self.attrValues[attribute]) == 1 and self.attrValues[attribute][0] == \"continuous\":\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def splitAttribute(self, curData, curAttributes):\n",
    "        splitted = []\n",
    "        maxEnt = -1*float(\"inf\")\n",
    "        best_attribute = -1\n",
    "        #None for discrete attributes, threshold value for continuous attributes\n",
    "        best_threshold = None\n",
    "        M = {}\n",
    "        for attribute in curAttributes:\n",
    "            indexOfAttribute = self.attributes.index(attribute)\n",
    "            if self.isAttrDiscrete(attribute):\n",
    "                #split curData into n-subsets, where n is the number of \n",
    "                #different values of attribute i. Choose the attribute with\n",
    "                #the max gain\n",
    "                valuesForAttribute = self.attrValues[attribute]\n",
    "                subsets = [[] for a in valuesForAttribute]\n",
    "                for row in curData:\n",
    "                    for index in range(len(valuesForAttribute)):\n",
    "                        if row[indexOfAttribute] == valuesForAttribute[index]:\n",
    "                            subsets[index].append(row)\n",
    "                            break\n",
    "                if self.s==0:\n",
    "                    e = self.gain(curData, subsets)\n",
    "                else:\n",
    "                    e = self.imprecise_gain(curData, subsets)\n",
    "                #if e > maxEnt:\n",
    "                #    maxEnt = e\n",
    "                #    splitted = subsets\n",
    "                #    best_attribute = attribute\n",
    "                #    best_threshold = None\n",
    "                M[(indexOfAttribute, None)] = (e, subsets)\n",
    "            else:\n",
    "                #sort the data according to the column.Then try all \n",
    "                #possible adjacent pairs. Choose the one that \n",
    "                #yields maximum gain\n",
    "                curData.sort(key = lambda x: x[indexOfAttribute])\n",
    "                for j in range(0, len(curData) - 1):\n",
    "                    if curData[j][indexOfAttribute] != curData[j+1][indexOfAttribute]:\n",
    "                        threshold = (curData[j][indexOfAttribute] + curData[j+1][indexOfAttribute]) / 2\n",
    "                        less = []\n",
    "                        greater = []\n",
    "                        for row in curData:\n",
    "                            if(row[indexOfAttribute] > threshold):\n",
    "                                greater.append(row)\n",
    "                            else:\n",
    "                                less.append(row)\n",
    "                        if self.s==0:\n",
    "                            e = self.gain(curData, [less, greater])\n",
    "                        else:\n",
    "                            e = self.imprecise_gain(curData, [less, greater])\n",
    "                        M[(indexOfAttribute, threshold)] = (e, [less,greater])\n",
    "                        #if e >= maxEnt:\n",
    "                        #    splitted = [less, greater]\n",
    "                        #    maxEnt = e\n",
    "                        #    best_attribute = attribute\n",
    "                        #    best_threshold = threshold\n",
    "        avg_e = np.mean([v[0] for v in M.values()])\n",
    "        M = {k:v for k,v in M.items() if v[0]>avg_e}\n",
    "        \n",
    "        if len(M)==0:\n",
    "            return None, None, None\n",
    "        try:\n",
    "            entrs = {k:self.entropy_attribute_subsets(v[1],k[0])\n",
    "                     for k,v in M.items()}\n",
    "            igsr = {k:v[0]/entrs[k] if entrs[k]>0 else 0\n",
    "                    for k,v in M.items()\n",
    "                   }\n",
    "            #igsr = {k:v[0] for k,v in M.items()}\n",
    "        except Exception as e:\n",
    "            print(M)\n",
    "        #    for k,v in M.items():\n",
    "        #        if sum(len(subs) for subs in v[1])>0:\n",
    "        #            #pass\n",
    "        #            print(k,v)\n",
    "        \n",
    "        #            print('-----------------------------')\n",
    "            raise e\n",
    "        \n",
    "        alpha = max(igsr.values())\n",
    "        best_attribute_idx, best_threshold = {v:k for k,v in igsr.items()}[alpha]\n",
    "        best_attribute = self.attributes[best_attribute_idx]\n",
    "        splitted = M[(best_attribute_idx, best_threshold)][1]\n",
    "        #print(best_attribute, best_threshold, )\n",
    "        return (best_attribute,best_threshold,splitted)\n",
    "\n",
    "    def gain(self,unionSet, subsets):\n",
    "        #input : data and disjoint subsets of it\n",
    "        #output : information gain\n",
    "        S = len(unionSet)\n",
    "        #calculate impurity before split\n",
    "        impurityBeforeSplit = self.entropy(unionSet)\n",
    "        #calculate impurity after split\n",
    "        weights = [len(subset)/S for subset in subsets]            \n",
    "        impurityAfterSplit = sum([weights[i]*self.entropy(subsets[i]) for i in range(len(subsets))])\n",
    "        #calculate total gain\n",
    "        totalGain = impurityBeforeSplit - impurityAfterSplit\n",
    "        return totalGain\n",
    "    \n",
    "    def imprecise_gain(self, unionSet, subsets):\n",
    "        S = len(unionSet)\n",
    "        impurityBeforeSplit = self.hstar(self.get_K(unionSet))\n",
    "        weights = self.get_pd(subsets)\n",
    "        impurityAfterSplit = sum([p*self.hstar(self.get_K(subs)) for p,subs in zip(weights, subsets)])\n",
    "        totalGain = impurityBeforeSplit - impurityAfterSplit\n",
    "        return totalGain\n",
    "    \n",
    "    def get_K(self, curData):\n",
    "        ps = [0]*len(self.classes)\n",
    "        for row in curData:\n",
    "            ps[self.classes.index(row[-1])]+=1\n",
    "        N = len(curData)\n",
    "        ps = [(p/(N+self.s),(p+self.s)/(N+self.s)) for p in ps]\n",
    "        return ps    \n",
    "\n",
    "    def hstar(self, K):\n",
    "        return max([-k_*self.log(k_) for k in K for k_ in np.arange(k[0], k[1]+1e-4, 1e-4)])\n",
    "\n",
    "    def get_B(self, subsets):\n",
    "        maxEnt = -1*float(\"inf\")\n",
    "        B = []\n",
    "        for idx,s in enumerate(subsets):\n",
    "            e = self.entropy(s)\n",
    "            if e==maxEnt:\n",
    "                B.append(idx)\n",
    "            if e>maxEnt:\n",
    "                maxEnt = e\n",
    "                B = [idx]\n",
    "        return B\n",
    "\n",
    "    def get_pd(self, subsets):\n",
    "        s = self.s\n",
    "        B = self.get_B(subsets)\n",
    "        N = sum([len(subs) for subs in subsets])\n",
    "        pds = [len(subs)/(N+s) if idx not in B else (len(subs)+s/len(B))/(N+s)\n",
    "               for idx,subs in enumerate(subsets)]\n",
    "        return pds\n",
    "\n",
    "    def entropy(self, dataSet):\n",
    "        S = len(dataSet)\n",
    "        if S == 0:\n",
    "            return 0\n",
    "        num_classes = [0]*len(self.classes)# [0 for i in self.classes]\n",
    "        for row in dataSet:\n",
    "            #print(row)\n",
    "            classIndex = list(self.classes).index(row[-1])\n",
    "            num_classes[classIndex] += 1\n",
    "        num_classes = [x/S for x in num_classes]\n",
    "        ent = -1*sum([num*self.log(num) for num in num_classes])\n",
    "        return ent\n",
    "\n",
    "    def log(self, x):\n",
    "        return math.log(x,2) if x!=0 else 0\n",
    "    \n",
    "    def entropy_attribute(self, data, attribute_idx):\n",
    "        value_counts = {}\n",
    "        for row in data:\n",
    "            value_counts[row[attribute_idx]] = value_counts.get(row[attribute_idx],0)+1\n",
    "        e = -sum([v/len(data)*self.log(v/len(data)) for v in value_counts.values()])\n",
    "        return e\n",
    "    \n",
    "    def entropy_attribute_subsets(self, subsets, attribute_idx):\n",
    "        try:\n",
    "            attribute = self.attributes[attribute_idx]\n",
    "            if self.attrValues[attribute]!=['continuous']:\n",
    "                return self.entropy_attribute([y for x in subsets for y in x], attribute_idx)\n",
    "        except Exception as e:\n",
    "            print(attribute_idx)\n",
    "            #print(attribute)\n",
    "            raise e\n",
    "        vs = [len(s) for s in subsets]\n",
    "        N = sum(vs)\n",
    "        e = -sum([v/N*self.log(v/N) for v in vs])\n",
    "        return e\n",
    "    \n",
    "\n",
    "class Node:\n",
    "    def __init__(self,isLeaf, label, threshold, height=None):\n",
    "        self.label = label\n",
    "        self.threshold = threshold\n",
    "        self.isLeaf = isLeaf\n",
    "        self.children = []\n",
    "        self.height = height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/hepatitis.names_short_very\",'r') as f:\n",
    "    columns = []\n",
    "    real_columns = []\n",
    "    cat_columns = []\n",
    "    for l in f.readlines():\n",
    "        n,t = [x.strip().replace(' ','_') for x in  l.split(':')]\n",
    "        if n=='y_feat':\n",
    "            y_feat = t\n",
    "            continue\n",
    "        columns.append(n)\n",
    "        if t=='categorical':\n",
    "            cat_columns.append(n)\n",
    "        elif t=='continuous':\n",
    "            real_columns.append(n)\n",
    "        else:\n",
    "            raise Exception(f\"Unknown datatype for columns {n}={t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('datasets/hepatitis.data', header=None)\n",
    "ds.columns = columns\n",
    "ds_new = ds.copy()\n",
    "for f in real_columns:\n",
    "    if f==y_feat:\n",
    "        continue\n",
    "    ds_new[f] = ds_new[f].replace('?',np.nan).astype(float)\n",
    "    ds_new[f] = ds_new[f].fillna(ds_new[f].mean())\n",
    "for f in cat_columns:\n",
    "    if f==y_feat:\n",
    "        continue\n",
    "    for v in ds_new[f].unique():\n",
    "        ds_new[f\"{f}__{v}\"] = (ds_new[f]==v).astype(int)\n",
    "    ds_new = ds_new.drop(f,1)\n",
    "ds_new = pd.concat([ds_new.drop(y_feat,1), ds_new[[y_feat]]],1)\n",
    "#ds_new = pd.concat([ds_new.iloc[:,1:],ds_new.iloc[:,0]],1)\n",
    "#ds[0] -= 1\n",
    "ds_new.to_csv('datasets/hepatitis.data_new', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#c1 = c45.C45(\"baris/data/iris/iris.data\", \"baris/data/iris/iris.names\")\n",
    "c2 = C45_credal(\"datasets/hepatitis.data_new\", \"datasets/hepatitis.names_short\", s=1)\n",
    "c2.fetchDataSet(ds_new, y_feat)\n",
    "all_data = [[y for y in x] for x in ds_new.values]\n",
    "#c2.preprocessData()\n",
    "#all_data = c2.data\n",
    "train_data, test_data = all_data[:int(len(all_data)*0.8)], all_data[int(len(all_data)*0.8):]\n",
    "c2.generateTree(train_data, c2.attributes)\n",
    "#c2.printTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trues = [x[-1] for x in test_data]\n",
    "preds = c2.predict_list(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5806451612903226"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(trues, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c3 = C45_credal(\"datasets/hepatitis.data_new\", \"datasets/hepatitis.names_short\", s=0)\n",
    "c3.fetchDataSet(ds_new, y_feat)\n",
    "all_data = [[y for y in x] for x in ds_new.values]\n",
    "train_data, test_data = all_data[:int(len(all_data)*0.8)], all_data[int(len(all_data)*0.8):]\n",
    "c3.generateTree(train_data, c3.attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trues = [x[-1] for x in test_data]\n",
    "preds = c3.predict_list(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5806451612903226"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(trues, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9a820ef52a459d863df6700fc2f084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acs = []\n",
    "for s in tqdm_notebook([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]):\n",
    "    c3 = C45_credal(\"datasets/hepatitis.data_new\", \"datasets/hepatitis.names_short\", s=s)\n",
    "    c3.fetchDataSet(ds_new, y_feat)\n",
    "    all_data = [[y for y in x] for x in ds_new.values]\n",
    "    train_data, test_data = all_data[:int(len(all_data)*0.8)], all_data[int(len(all_data)*0.8):]\n",
    "    c3.generateTree(train_data, c3.attributes)\n",
    "    trues = [x[-1] for x in test_data]\n",
    "    preds = c3.predict_list(test_data)\n",
    "    acs.append(accuracy_score(trues, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
